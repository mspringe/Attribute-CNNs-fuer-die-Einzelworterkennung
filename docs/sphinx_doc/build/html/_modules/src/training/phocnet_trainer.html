


<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>src.training.phocnet_trainer &#8212; Attribute CNNs für die Einzelworterkennung August 12 2019 documentation</title>
    <link rel="stylesheet" href="../../../_static/p_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/local_fonts.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../_static/jquery.cookie.js"></script>
    <script type="text/javascript" src="../../../_static/p_sphinx_theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
            <meta name="viewport" content="width=device-width, initial-scale=1">
  </head><body>
      <div class="relbar-top">
            
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> &nbsp; &nbsp;</li>
      <li><a href="../../../index.html">Attribute CNNs für die Einzelworterkennung August 12 2019 documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for src.training.phocnet_trainer</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Training script, used for the PHOCNet.</span>

<span class="sd">Output will be written to the directory specified as dir_out.</span>
<span class="sd">Each model has its own directory containing:</span>

<span class="sd">    * The log file</span>
<span class="sd">    * The final state-dictionary</span>
<span class="sd">    * A config JSON file of the arguments provided to the script</span>
<span class="sd">    * A config JSON file of PHOCNet (stating the PHOCNets configuration)</span>
<span class="sd">    * A directory &quot;tmp&quot; containing state-dictionaries, that have been saved during training</span>


<span class="sd">Example for training the PHOCNet:</span>

<span class="sd">::</span>

<span class="sd">    python3 src/training/phocnet_trainer.py \\</span>
<span class="sd">    path/to/output_dir/ \\</span>
<span class="sd">    gw \\</span>
<span class="sd">    path/to/gw_database/almazan/queries/queries.gtp \\</span>
<span class="sd">    path/to/gw_database/almazan/images \\</span>
<span class="sd">    --max_iter=1e5 \\</span>
<span class="sd">    --model_name=my_PHOCNet \\</span>
<span class="sd">    --gpu_idx=cuda:0 \\</span>
<span class="sd">    --k_fold=1 \\</span>
<span class="sd">    --alphabet=ldp \\</span>
<span class="sd">    --s_batch=10</span>

<span class="sd">See also :func:`src.parser.args_parser.parser_training` for all options, regarding training.</span>

<span class="sd">.. moduleauthor:: Maximilian Springenberg &lt;mspringenberg@gmail.com&gt;</span>

<span class="sd">|</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="c"># general libraries</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="c"># pytorch relevant imports</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="c"># own libs</span>
<span class="n">FILE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">__file__</span><span class="p">))</span>
<span class="n">SRC_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">FILE_DIR</span><span class="p">,</span> <span class="s">&#39;..&#39;</span><span class="p">,</span> <span class="s">&#39;..&#39;</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="p">))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SRC_DIR</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">FILE_DIR</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">src.nn</span> <span class="k">import</span> <span class="n">phocnet</span>
<span class="kn">from</span> <span class="nn">src.io.dataloader</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">src.util</span> <span class="k">import</span> <span class="n">phoc_util</span><span class="p">,</span> <span class="n">sanity_util</span>
<span class="kn">from</span> <span class="nn">src.util.phoc_util</span> <span class="k">import</span> <span class="n">Alphabet</span>
<span class="kn">from</span> <span class="nn">src.parser.args_parser</span> <span class="k">import</span> <span class="n">parser_training</span> <span class="k">as</span> <span class="n">parser</span>
<span class="kn">from</span> <span class="nn">src.parser.to_data</span> <span class="k">import</span> <span class="o">*</span>


<div class="viewcode-block" id="Trainer"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.Trainer">[docs]</a><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;generic trainer of models&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span> <span class="p">:</span> <span class="n">phocnet</span><span class="o">.</span><span class="n">PHOCNet</span><span class="p">,</span> <span class="n">net_log_dir</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(),</span> <span class="n">s_batch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>
                 <span class="n">logger</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">augmented</span><span class="o">=</span><span class="k">True</span><span class="p">,</span> <span class="n">s_aug</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span> <span class="n">quant_aug</span><span class="o">=</span><span class="n">DSetQuant</span><span class="o">.</span><span class="n">EQUAL</span><span class="p">,</span> <span class="n">tmp_save_mod</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                 <span class="n">alphabet</span><span class="o">=</span><span class="p">[</span><span class="n">Alphabet</span><span class="o">.</span><span class="n">ASCII_LOWER</span><span class="p">,</span> <span class="n">Alphabet</span><span class="o">.</span><span class="n">ASCII_DIGITS</span><span class="p">,</span> <span class="n">Alphabet</span><span class="o">.</span><span class="n">ASCII_PUNCTUATION</span><span class="p">],</span>
                 <span class="n">phoc_lvls</span><span class="o">=</span><span class="n">phoc_util</span><span class="o">.</span><span class="n">DEFAULT_PHOC_LEVELS</span><span class="p">,</span> <span class="n">mixed_precision</span><span class="o">=</span><span class="k">False</span><span class="p">,</span> <span class="n">FP</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="c"># globals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span> <span class="o">=</span> <span class="n">alphabet</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phoc_lvls</span> <span class="o">=</span> <span class="n">phoc_lvls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_log_dir</span> <span class="o">=</span> <span class="n">net_log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_batch</span> <span class="o">=</span> <span class="n">s_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__device</span> <span class="o">=</span> <span class="k">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">augmented</span> <span class="o">=</span> <span class="n">augmented</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aug_size</span> <span class="o">=</span> <span class="n">s_aug</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aug_quant</span> <span class="o">=</span> <span class="n">quant_aug</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tmp_save_mod</span> <span class="o">=</span> <span class="n">tmp_save_mod</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mixed_precision</span> <span class="o">=</span> <span class="n">mixed_precision</span>
        <span class="c"># properties</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">FP</span> <span class="o">=</span> <span class="n">FP</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;device the NN shall run on&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;changing the device to run on&quot;&quot;&quot;</span>
        <span class="c"># moving to gpu if a device is provided</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="c"># going back to cpu otherwise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__device</span> <span class="o">=</span> <span class="n">device</span>

<div class="viewcode-block" id="Trainer.train_on"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.Trainer.train_on">[docs]</a>    <span class="k">def</span> <span class="nf">train_on</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_set</span><span class="p">:</span> <span class="n">DSetPhoc</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">1</span><span class="n">e5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The training loop</span>

<span class="sd">        :param d_set: Dataset to run on</span>
<span class="sd">        :param optimizer: Optimizer (e.g. :class:`optim.SGD`, :class:`optim.Adam`)</span>
<span class="sd">        :param n_iter: Number of iterations to be run</span>
<span class="sd">        :param shuffle: Indicates whether data shall be shuffled each epoch, True by default</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># applying PHOC-settings to the dataset</span>
        <span class="n">d_set</span><span class="o">.</span><span class="n">alphabet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span>
        <span class="n">d_set</span><span class="o">.</span><span class="n">phoc_levels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">phoc_lvls</span>
        <span class="c"># applying augmentation settings to the dataset</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;initializing augmented training data&#39;</span><span class="p">)</span>
            <span class="n">d_set</span> <span class="o">=</span> <span class="n">d_set</span><span class="o">.</span><span class="n">augment</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aug_size</span><span class="p">,</span> <span class="n">t_quant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aug_quant</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;done, training on dataset of size {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d_set</span><span class="p">)))</span>
        <span class="c"># making sure the logging dir exists</span>
        <span class="n">sanity_util</span><span class="o">.</span><span class="n">safe_dir_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net_log_dir</span><span class="p">)</span>
        <span class="c"># empty batch and respective embeddings (batches via tensor not feasible, since images may vary in scale)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c"># keeping track of iterations</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c"># training</span>
        <span class="c"># keeping track of the mean error</span>
        <span class="n">mean_batch_err</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c"># running the epochs</span>
        <span class="n">training</span> <span class="o">=</span> <span class="k">True</span>
        <span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">training</span><span class="p">:</span>
            <span class="c"># initialize train-data as shuffled (updating iterator each epoch, to decrease likelihood of overfitting)</span>
            <span class="n">d_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">d_set</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">d_loader</span><span class="p">):</span>
                <span class="c"># collecting the batch</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;img&#39;</span><span class="p">]</span>
                <span class="n">emb</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;phoc&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_batch</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d_set</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
                    <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c"># processing batch</span>
                    <span class="n">mean_batch_err</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
                    <span class="c"># counting iterations</span>
                    <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="c"># emptying batch</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="c"># optimizer step</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="c"># making sure not to exceed maximum iterations during epoch</span>
                <span class="k">if</span> <span class="nb">iter</span> <span class="o">&gt;=</span> <span class="n">n_iter</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="c"># logging</span>
                <span class="c"># logging mean batch error every 1000 iterations</span>
                <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">tmp_err</span> <span class="o">=</span> <span class="n">mean_batch_err</span> <span class="o">/</span> <span class="mi">1000</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_batch</span>
                    <span class="n">mean_batch_err</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;iteration {}/ {} ended, mean error {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">tmp_err</span><span class="p">))</span>
                    <span class="c"># saving net state-dict in intervals (default 10000 iterations)</span>
                    <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">tmp_save_mod</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">tmp_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net_log_dir</span><span class="p">,</span> <span class="s">&#39;epoch_{}_iter{}.pth&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="nb">iter</span><span class="p">))</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">tmp_path</span><span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;iteration {}/ {} ended, wrote net to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">tmp_path</span><span class="p">))</span>
                    <span class="c"># changing learning rate after 60,000 iterations (dividing by 10)</span>
                    <span class="c"># or changing learning rate every 100,000 iterations starting with the 200,000th iteration</span>
                    <span class="k">if</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">%</span> <span class="mi">60000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">iter</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">%</span> <span class="mi">200000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span> <span class="c">#or (iter &gt;= 200000 and iter % 100000 == 0):</span>
                        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                            <span class="n">param_group</span><span class="p">[</span><span class="s">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_group</span><span class="p">[</span><span class="s">&#39;lr&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span>
            <span class="c"># making sure not to exceed maximum iterations after epoch</span>
            <span class="k">if</span> <span class="nb">iter</span> <span class="o">&gt;=</span> <span class="n">n_iter</span><span class="p">:</span>
                <span class="n">training</span> <span class="o">=</span> <span class="k">False</span>
                <span class="k">break</span>
            <span class="c"># logging after batch</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;epoch {} ended&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
            <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span></div>

<div class="viewcode-block" id="Trainer.train_on_batch"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.Trainer.train_on_batch">[docs]</a>    <span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs forward and backwards propagation on a given batch</span>

<span class="sd">        :param batch: batch to be processed</span>
<span class="sd">        :param embeddings: respective embeddings</span>
<span class="sd">        :return: summed losses of the batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">err</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c"># input images of individual sizes --&gt; individual forward passes</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">([</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">e</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">emb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
                <span class="c"># conversion to correct tensor</span>
                <span class="n">x_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">img</span><span class="o">.</span><span class="n">numpy</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
                <span class="n">y_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">emb</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
                <span class="c"># auto-grading</span>
                <span class="n">x_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
                <span class="n">y_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">y_emb</span><span class="p">)</span>
                <span class="c"># moving to gpu</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
                    <span class="n">x_in</span> <span class="o">=</span> <span class="n">x_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">y_emb</span> <span class="o">=</span> <span class="n">y_emb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="c"># forward pass</span>
                <span class="n">x_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
                <span class="c"># calculating loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_out</span><span class="p">,</span> <span class="n">y_emb</span><span class="p">)</span>
                <span class="c"># backward propagation</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="c"># summing losses</span>
                <span class="n">err</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c"># fixed input size --&gt; faster forward pass, via one stacked tensor</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
            <span class="n">y_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">e</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">embeddings</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
            <span class="c"># auto-grading</span>
            <span class="n">x_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
            <span class="n">y_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">y_emb</span><span class="p">)</span>
            <span class="c"># moving to gpu</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="k">None</span><span class="p">:</span>
                <span class="n">x_in</span> <span class="o">=</span> <span class="n">x_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_emb</span> <span class="o">=</span> <span class="n">y_emb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="c"># forward pass</span>
            <span class="n">x_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
            <span class="c"># calculating loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_out</span><span class="p">,</span> <span class="n">y_emb</span><span class="p">)</span>
            <span class="c"># backward propagation</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c"># summing losses</span>
            <span class="n">err</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c"># moving to cpu</span>
        <span class="n">x_in</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">y_emb</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">x_in</span>
        <span class="k">del</span> <span class="n">y_emb</span>
        <span class="k">return</span> <span class="n">err</span></div>

<div class="viewcode-block" id="Trainer.set_up"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.Trainer.set_up">[docs]</a>    <span class="k">def</span> <span class="nf">set_up</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;dictionary with meta data of training&quot;&quot;&quot;</span>
        <span class="n">t_loss_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">augmeted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented</span>
        <span class="n">s_augmented</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aug_size</span>
        <span class="n">quant_augmented</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aug_quant</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">&#39;f_loss&#39;</span><span class="p">:</span> <span class="n">t_loss_str</span><span class="p">,</span> <span class="s">&#39;augmentation&#39;</span><span class="p">:</span> <span class="n">augmeted</span><span class="p">,</span> <span class="s">&#39;augmentation_size&#39;</span><span class="p">:</span> <span class="n">s_augmented</span><span class="p">,</span>
                <span class="s">&#39;augmentation_quantification&#39;</span><span class="p">:</span> <span class="n">quant_augmented</span><span class="p">,</span> <span class="s">&#39;nn_setup&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">setup</span><span class="p">(),</span>
                <span class="s">&#39;alphabet&#39;</span><span class="p">:</span> <span class="n">phoc_util</span><span class="o">.</span><span class="n">alphabet_to_rep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphabet</span><span class="p">),</span> <span class="s">&#39;phoc_lvls&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">phoc_lvls</span><span class="p">}</span></div>

<div class="viewcode-block" id="Trainer.save"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.Trainer.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dir_out</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">pfx</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;saving the NN, aswell as all relevant meta-data&quot;&quot;&quot;</span>
        <span class="c"># creating save path</span>
        <span class="n">sanity_util</span><span class="o">.</span><span class="n">safe_dir_path</span><span class="p">(</span><span class="n">dir_out</span><span class="p">)</span>
        <span class="c"># not deleting prior data</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">sanity_util</span><span class="o">.</span><span class="n">unique_file_name</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="s">&#39;nn_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pfx</span><span class="p">),</span> <span class="n">suffix</span><span class="o">=</span><span class="s">&#39;.pth&#39;</span><span class="p">)</span>
        <span class="n">file_path_setup</span> <span class="o">=</span> <span class="n">sanity_util</span><span class="o">.</span><span class="n">unique_file_name</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="s">&#39;setup_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pfx</span><span class="p">),</span> <span class="n">suffix</span><span class="o">=</span><span class="s">&#39;.json&#39;</span><span class="p">)</span>
        <span class="c"># writing nn</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">file_path</span><span class="p">)</span>
        <span class="c"># writing the training setup</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path_setup</span><span class="p">,</span> <span class="s">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_json</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">set_up</span><span class="p">(),</span> <span class="n">f_json</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="sgd_optimizer"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.sgd_optimizer">[docs]</a><span class="k">def</span> <span class="nf">sgd_optimizer</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;standard SGD optimizer&quot;&quot;&quot;</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span></div>


<div class="viewcode-block" id="adam_optimizer"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.adam_optimizer">[docs]</a><span class="k">def</span> <span class="nf">adam_optimizer</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;adam optimizer as proposed in the Retsinas paper&quot;&quot;&quot;</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.00005</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span></div>


<div class="viewcode-block" id="new_logger"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.new_logger">[docs]</a><span class="k">def</span> <span class="nf">new_logger</span><span class="p">(</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;initializes a logger for training&quot;&quot;&quot;</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">dir_out</span> <span class="o">=</span> <span class="n">sanity_util</span><span class="o">.</span><span class="n">safe_dir_path</span><span class="p">(</span><span class="n">dir_out</span><span class="p">)</span>
    <span class="n">log_file_path</span> <span class="o">=</span> <span class="n">sanity_util</span><span class="o">.</span><span class="n">unique_file_name</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">&#39;.log&#39;</span><span class="p">)</span>
    <span class="n">hdlr</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">FileHandler</span><span class="p">(</span><span class="n">log_file_path</span><span class="p">)</span>
    <span class="n">formatter</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">Formatter</span><span class="p">(</span><span class="s">&#39;%(asctime)s %(levelname)s %(message)s&#39;</span><span class="p">)</span>
    <span class="n">hdlr</span><span class="o">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">formatter</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">hdlr</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logger</span></div>


<div class="viewcode-block" id="CosineLoss"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.CosineLoss">[docs]</a><span class="k">class</span> <span class="nc">CosineLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Cosine Loss has no native implementation in pytorch, hence this Module class (see :class:`nn.Module`).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="k">True</span><span class="p">,</span> <span class="n">use_sigmoid</span><span class="o">=</span><span class="k">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CosineLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">averaging</span> <span class="o">=</span> <span class="n">size_average</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_sigmoid</span> <span class="o">=</span> <span class="n">use_sigmoid</span>

<div class="viewcode-block" id="CosineLoss.forward"><a class="viewcode-back" href="../../../src.training.phocnet_trainer.html#src.training.phocnet_trainer.CosineLoss.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_var</span><span class="p">,</span> <span class="n">target_var</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        calculates the cosine loss: :math:`1.0 - (y.x / |y|*|x|)`</span>

<span class="sd">        :param input_var: estimated vector</span>
<span class="sd">        :param target_var: embedding</span>
<span class="sd">        :return: cosine loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_sigmoid</span><span class="p">:</span>
            <span class="n">loss_val</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">input_var</span><span class="p">),</span> <span class="n">target_var</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_val</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">input_var</span><span class="p">,</span> <span class="n">target_var</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">averaging</span><span class="p">:</span>
            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_val</span><span class="o">/</span><span class="n">input_var</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">loss_val</span></div></div>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">t_start_training</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">asctime</span><span class="p">()</span>
    <span class="sd">&quot;&quot;&quot;arg parser&quot;&quot;&quot;</span>
    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">parser</span><span class="p">()</span>
    <span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>
    <span class="c"># FP16 vs FP32</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span> <span class="c">#torch.float16 if int(args[&#39;FP&#39;]) == 16 else torch.float32</span>
    <span class="c"># src dir of the dataset</span>
    <span class="n">dset_csv</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;dset_csv&#39;</span><span class="p">]</span>
    <span class="n">dset_src</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;dset_src&#39;</span><span class="p">]</span>
    <span class="c"># fold number/ index</span>
    <span class="n">k_fold</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;k_fold&#39;</span><span class="p">])</span>
    <span class="c"># scale of imgs</span>
    <span class="n">scale_str</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;scale_w&#39;</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;scale_h&#39;</span><span class="p">]</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">scale_str</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">scale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">scale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>
    <span class="c"># figuring out which dataset to use and under which protocol</span>
    <span class="n">phoc_lvls</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;phoc_lvls&#39;</span><span class="p">])</span>
    <span class="n">alphabet</span> <span class="o">=</span> <span class="n">phoc_util</span><span class="o">.</span><span class="n">rep_to_alphabet</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;alphabet&#39;</span><span class="p">])</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;stop_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;true&#39;</span><span class="p">,</span> <span class="s">&#39;1&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">,</span> <span class="s">&#39;yes&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">]</span>
    <span class="n">punctuation</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;punctuation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;true&#39;</span><span class="p">,</span> <span class="s">&#39;1&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">,</span> <span class="s">&#39;yes&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">]</span>
    <span class="n">dset_name</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;dset_name&#39;</span><span class="p">]</span>
    <span class="n">data_set</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">get_dsets</span><span class="p">(</span><span class="n">dset_name</span><span class="p">,</span> <span class="n">dset_csv</span><span class="p">,</span> <span class="n">dset_src</span><span class="p">,</span> <span class="n">alphabet</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">k_fold</span><span class="p">,</span> <span class="n">phoc_lvls</span><span class="p">)</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">apply_alphabet</span><span class="p">(</span><span class="n">alphabet</span><span class="p">)</span>
    <span class="c"># name of gpu device</span>
    <span class="n">gpu_idx</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;gpu_idx&#39;</span><span class="p">]</span>
    <span class="c"># number of maximum training epochs and iterations</span>
    <span class="n">max_iter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;max_iter&#39;</span><span class="p">]))</span>
    <span class="c"># name of model</span>
    <span class="n">model_pfx</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;model_name&#39;</span><span class="p">]</span>
    <span class="c"># directory to save the NN at</span>
    <span class="n">dir_out</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;dir_out&#39;</span><span class="p">],</span> <span class="n">model_pfx</span><span class="p">)</span>
    <span class="c"># optimizer to be used</span>
    <span class="n">optim_type_str</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;optimizer&#39;</span><span class="p">]</span>
    <span class="c"># net type to be used</span>
    <span class="n">net_type_str</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;PHOCNet_type&#39;</span><span class="p">]</span>
    <span class="c"># loss function, used in training</span>
    <span class="n">loss_str</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;loss&#39;</span><span class="p">]</span>

    <span class="sd">&quot;&quot;&quot;initialize logging&quot;&quot;&quot;</span>
    <span class="n">log</span> <span class="o">=</span> <span class="n">new_logger</span><span class="p">(</span><span class="n">dir_out</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">model_pfx</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;intialize the PHOCNet&quot;&quot;&quot;</span>
    <span class="c"># choose module</span>
    <span class="n">phoc_net</span> <span class="o">=</span> <span class="n">get_PHOCNet</span><span class="p">(</span><span class="n">net_type_str</span><span class="p">,</span> <span class="n">alphabet</span><span class="p">,</span> <span class="n">phoc_lvls</span><span class="p">)</span>
    <span class="c"># weight initialization</span>
    <span class="n">p_pretrained</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;pretrained&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">p_pretrained</span><span class="p">):</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">p_pretrained</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="c"># un-strict loading enables STNPHOCNet instances to be (partially) initialized with PHOCNet instances</span>
        <span class="n">phoc_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">phoc_net</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="sd">&quot;&quot;&quot;initialize optimizer&quot;&quot;&quot;</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;lr&#39;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">optim_type_str</span> <span class="o">==</span> <span class="s">&#39;sgd&#39;</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd_optimizer</span><span class="p">(</span><span class="n">phoc_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam_optimizer</span><span class="p">(</span><span class="n">phoc_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;initialize trainer&quot;&quot;&quot;</span>
    <span class="n">augment_dset</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;augment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">REP_STRS</span>
    <span class="n">t_augment</span> <span class="o">=</span> <span class="n">rep_to_quant</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;augment&#39;</span><span class="p">])</span>
    <span class="n">intv_save</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;save_interval&#39;</span><span class="p">])</span>
    <span class="n">s_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">&#39;s_batch&#39;</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">gpu_idx</span><span class="p">)</span> <span class="k">if</span> <span class="n">gpu_idx</span> <span class="o">!=</span> <span class="s">&#39;none&#39;</span> <span class="k">else</span> <span class="k">None</span>
    <span class="k">if</span> <span class="n">loss_str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s">&#39;bce&#39;</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">CosineLoss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="k">False</span><span class="p">,</span> <span class="n">use_sigmoid</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="n">phoc_net</span><span class="p">,</span> <span class="n">net_log_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_out</span><span class="p">,</span> <span class="s">&#39;tmp&#39;</span><span class="p">,</span> <span class="n">model_pfx</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="p">),</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="n">log</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">s_batch</span><span class="o">=</span><span class="n">s_batch</span><span class="p">,</span> <span class="n">augmented</span><span class="o">=</span><span class="n">augment_dset</span><span class="p">,</span> <span class="n">tmp_save_mod</span><span class="o">=</span><span class="n">intv_save</span><span class="p">,</span>
                      <span class="n">alphabet</span><span class="o">=</span><span class="n">alphabet</span><span class="p">,</span> <span class="n">phoc_lvls</span><span class="o">=</span><span class="n">phoc_lvls</span><span class="p">,</span> <span class="n">quant_aug</span><span class="o">=</span><span class="n">t_augment</span><span class="p">,</span> <span class="n">FP</span><span class="o">=</span><span class="n">FP</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;run training&quot;&quot;&quot;</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">&#39;shuffle&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;true&#39;</span><span class="p">,</span> <span class="s">&#39;1&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">,</span> <span class="s">&#39;yes&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">]</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_on</span><span class="p">(</span><span class="n">d_set</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;save net&quot;&quot;&quot;</span>
    <span class="n">ids_train</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">ids_test</span> <span class="o">=</span> <span class="n">test_set</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">dir_out</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">ids_train</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="n">ids_test</span><span class="p">,</span> <span class="n">pfx</span><span class="o">=</span><span class="n">model_pfx</span><span class="p">)</span>
    <span class="sd">&quot;&quot;&quot;saving args, so you have a reference to the training-config of your model&quot;&quot;&quot;</span>
    <span class="n">sanity_util</span><span class="o">.</span><span class="n">safe_dir_path</span><span class="p">(</span><span class="n">dir_out</span><span class="p">)</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">sanity_util</span><span class="o">.</span><span class="n">unique_file_name</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_out</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="s">&#39;args_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model_pfx</span><span class="p">),</span> <span class="n">suffix</span><span class="o">=</span><span class="s">&#39;.json&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">args_out</span><span class="p">:</span>
        <span class="n">t_end_training</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">asctime</span><span class="p">()</span>
        <span class="n">args</span><span class="p">[</span><span class="s">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;started&#39;</span><span class="p">:</span> <span class="n">t_start_training</span><span class="p">,</span> <span class="s">&#39;ended&#39;</span><span class="p">:</span> <span class="n">t_end_training</span><span class="p">}</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">args_out</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
      <div class="relbar-bottom">
            
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> &nbsp; &nbsp;</li>
      <li><a href="../../../index.html">Attribute CNNs für die Einzelworterkennung August 12 2019 documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Maximilian Rüdiger Springenberg.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.3.0.
    </div>
      <!-- PSphinxTheme -->
  </body>
</html>